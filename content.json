{"pages":[],"posts":[{"title":"Add Two Numbers","text":"題目思路： 既然 Linked List 是由個位數開始，剛好可以用小學學的加法來從個位數開始相加。所以須設計一個迴圈來執行可重複執行的加法動作，一步步構建答案所需的 linked list，一次建立一個 node，直到完成。 迴圈要可重複執行，需要有個指標，在迴圈內對該指標所指的 node 做操作，並在迴圈結束時讓指標指到下一個 node，讓下一次迴圈來操作 迴圈內算出的當下位數的答案 digit_sum % 10 的 node 為何是指定給 curr.next 而非 curr? 因為迴圈結束前 curr 必須指向下一個 node，也就是 curr.next，以下分兩種情況解釋： 答案放在 curr 身上：必須創造一個空的 node 來當 curr.next，而假如這次的迴圈已經是最後一次了，此 linked list 的尾巴就會多一個空的 node 答案放在 curr.next 身上：迴圈結束前 curr 指向 curr.next 繼續下一次的操作，假如此次已是最後一次迴圈，也不會多出空的 node 在 linked list 末端，只會在開頭多出一個沒用到的 dummy_head 而已，因此最後回傳答案時是回傳 dummy_head.next Python3 solution 1234567891011121314def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]: carry = 0 # 位數相加後除以 10 得到的商 dummy_head = ListNode() # 用 dummy_head 保留最前面的指標，到時候才有辦法回傳答案 curr = dummy_head # 不能只用 `curr = ListNode()`，因為 `curr` 所指的 node 必須一直變 while l1 or l2 or carry: # 可以繼續加的條件 v1 = l1 and l1.val or 0 v2 = l2 and l2.val or 0 digit_sum = v1 + v2 + carry carry = digit_sum // 10 curr.next = ListNode(digit_sum % 10) curr = curr.next l1 = l1 and l1.next l2 = l2 and l2.next return dummy_head.next","link":"/add-two-numbers/"},{"title":"在 Mac 加入 ssh key 的步驟","text":"ssh-keygen -t ed25519 -C &quot;{你的 email}&quot; 預設路徑假如已有相同檔案，記得指定新的完整路徑 如檔名不用預設的，下面 id_ed25519 自行替換成自己的檔名 vi ~/.ssh/config 舉例：加上如下 1234Host GitHub HostName github.com IdentityFile ~/.ssh/id_ed25519 IdentitiesOnly yes ssh-add -K ~/.ssh/id_ed25519 register your private key with ssh-agent pbcopy &lt; ~/.ssh/id_ed25519.pub 貼到所使用的服務網站的相對應設定頁面","link":"/add-ssh-steps/"},{"title":"3Sum","text":"題目思路： 用三個指標，iterate 最左邊那個，找出對應於每個 left 指標的所有 result 先把 nums 排序，如此移動 mid, right 指標時就有個依據 Python3 solution 1234567891011121314151617181920212223242526def threeSum(self, nums): result = [] nums.sort() for left in range(len(nums) - 2): # 右邊須留兩個空位給另兩個指標 if left &gt; 0 and nums[left] == nums[left - 1]: # 排除重複的 result，left 必須 &gt; 0 才會有前一個 continue # - 假如 nums[left] 是一樣的，最後找到的 result 也會是一樣的，所以要排除掉 mid = left + 1 right = len(nums) - 1 while mid &lt; right: # 設定有效範圍，在此範圍內尋找符合的 mid, right t_sum = nums[left] + nums[mid] + nums[right] if t_sum &lt; 0: mid += 1 # 此時必須讓 t_sum 變大，所以將 mid 往右移 elif t_sum &gt; 0: right -= 1 # 此時必須讓 t_sum 變小，所以將 right 往左移 else: result.append([nums[left], nums[mid], nums[right]]) while mid &lt; right and nums[mid] == nums[mid + 1]: # 跳過 mid 重複的部分 mid += 1 while mid &lt; right and nums[right] == nums[right - 1]: # 跳過 right 重複的部分 right -= 1 # 正常的移動 mid, right，尋找下一個符合的 result mid += 1 right -= 1 return result","link":"/3-sum/"},{"title":"844. Backspace String Compare","text":"題目這邊記錄自己答案的演變和檢討，有需要的也可以直接跳到最後的 O(1) space complexity 解答 一開始的思路：用遞增的 index 同時 go through 這兩個字串，按照裡面的 backspace hint build 出兩個新的字串再來看看是否相等 Python 3 solution at first12345678910111213141516171819202122def backspaceCompare(self, s: str, t: str) -&gt; bool: new_t, new_s = '', '' for i in range(max(len(s), len(t))): try: sc = s[i] except: pass else: if sc == '#' and new_s: new_s = new_s[:len(new_s) - 1] # Remove new_s's last character elif sc != '#': new_s += sc try: tc = t[i] except: pass else: if tc == '#' and new_t: new_t = new_t[:len(new_t) - 1] # Remove new_t's last character elif tc != '#': new_t += tc return new_t == new_s 缺點：每次遇到 # 就會有個 O(k) 的操作改進：假如用 list 來放字元，pop() 只有 O(1)，再用 O(m) 的 str.join 合成最終的字串(1 &lt;= k &lt; n, 1 &lt;= m &lt;= n, n 為字串長度) improved Python 3 solution12345678910def backspaceCompare(self, s: str, t: str) -&gt; bool: def build(s): arr = [] for c in s: if c != '#': arr.append(c) elif arr: arr.pop() return ''.join(arr) return build(s) == build(t) 時間和空間複雜度都是 O(n) 題目的 Follow up: Can you solve it in O(n) time and O(1) space?思路 不能用額外的 array 來儲存新的字串，那就只能使用 pointer 來 go through 字串，一個個字母依序比較 假如從頭開始 go through 有點困難，因為你不知道當前的字母會不會在之後被刪除，那從後往前可以嗎？ 從後往前的話可以。因為只要遇到當前字母之前都沒有 #，該字母就一定會在最終字串裡，而我們一樣可以比較每個字母來判斷兩個字串最終是否相等，當遇到 # 時也可以很容易地跳過 必須要有一個 function for s 和 t，讓我們可以傳入字串和 index，告訴我們： 從那個 index 開始往前的話，下一個合法字母是什麼 下一個 index 從哪邊開始 Final Python 3 solution12345678910111213141516171819202122232425def backspaceCompare(self, s: str, t: str) -&gt; bool: def get_next_char(string: str, index: int) -&gt; tuple: \"\"\"Helper function to get the next valid character and the next index in the string\"\"\" skip = 0 while index &gt;= 0: if string[index] == '#': skip += 1 elif skip &gt; 0: skip -= 1 else: return string[index], index - 1 index -= 1 return None, -1 i = len(s) - 1 j = len(t) - 1 while i &gt;= 0 or j &gt;= 0: char_s, i = get_next_char(s, i) char_t, j = get_next_char(t, j) if char_s != char_t: return False return True","link":"/backspace-string-compare/"},{"title":"趨勢科技的 agile tour_by Joy Chen 心得分享 - Agile Tour Taipei 2014","text":"failed getting oembed item.(url=http://www.slideshare.net/AgileCommunity/agile-tour-agile-v3) 上禮拜參加 Agile Tour Taipei 2014，第一場 talk 的 Joy 分享趨勢科技實行 Agile 的經驗，上面是她的 slides Agile 的優點與適用情境 下面是第 9 張 slide，以追蹤導彈和固定火炮來比喻 Agile Mentality 和 Plan Driven 的差別我覺得這個比喻很好，一張圖就可以讓大家清楚的看到 Agile 的優點：隨著目標(專案需求)的改變而在每一次的 iteration調整方向，重新瞄準目標，最後才能準確地擊中目標相對來講假如是 Plan Driven(固定火炮) 的話，只要目標一動就無法命中目標了。 上面講 agile mentality 適合用在 moving target，但其實如同 Joy 的下一張 slide 所提，適合 Agile Principles 的情境還有很多，其中我覺得 Moving Target 和 Continuous Improvement 是對我來講最有感覺的 Moving Target: Uncertain situation: 假如是新創公司面對一個不確定的市場，就必須要快速取得市場反饋，快速修正 Brand new knowledge: 面對新的領域、新的知識，一定有很多未知、不確定的事情，此時一樣需要快速的反省與修正 As early as possible needs: 每個 iteration 結束都會有一個可以 ship 的成品，所以如果需要及早的有實際的成品的話也很適合 Continuous Improvement: Continuously improve a certain capability, practice or skill: 因為每個 iteration 結束都會做回顧，所以可以快速地檢視需要改進的地方，並且快速修正 Lessons Learned Joy 也分享了趨勢在推行 agile 的時候學到的教訓 牛肉在哪裡？ 因為向上司報告專案成果時沒有事先準備資料來說明實行 agile 之後改善的地方，上司沒有看到牛肉，所以也不會覺得改用 agile 的方式開發之後有甚麼好 解法：在進行agile的時候就要把專案進度相關數據記錄下來，在進度報告時明確點出改善之處 我們不幹了！ 一開始實施新的方法，一定會有一段磨合期，假如沒有事先把這段時間算入時程，就會導致必須要不斷加班趕進度的狀況，Joy 有分享一個例子是他們有一個 project 的 team 在 project 完成之後大概流失了一半的人 解法：實施新方法的時候，一定要把磨合的時間也算進去 送不出去的價值！ 當只有開發團隊實施 agile，其他團隊沒有配合，會導致每個iteration的成品無法進入下個階段 解法：必須要所有團隊一起採用 agile 才能真正發揮 agile 的成效，至於詳細的實作方法他們也還在嘗試中","link":"/agile-tour-thoughts/"},{"title":"Android 連續掃描多個 QR code 的實作","text":"使用 GitHub 上 LivotovLabs/zxscanlib 的 v0.9.0 版，目前上面有更新的版本，不過我那時候用的時候最新的就到這版 假如直接使用這個 library ，手機在掃到 QR code 的時候會震動，然後離開掃描的相機畫面回到前一個畫面，另外，它開相機的時候會把畫面變成橫的(landscape)。所以要達到我的要求的話就需要改一下裡面的 code，這邊分享一下把這個 library 應用到可以連續掃描多個 QR code 的經驗 (使用eclipse)，可以搭配該 project 的 GitHub 頁面說明一起看 目標：可以連續掃描多個 QR code，當掃到目標 QR code 的時候跳回原畫面，並使用取得的資料做下一步應用Dependency Issue把 project clone 下來之後，照著 GitHub 頁面上的說明，將它當作一個 library project 使用，此時假如原本的 project 有用到 android-support-v4.jar，就會產生衝突(因為此 library project 也有用)，我的解決方式是把原本 project 的 android-support-v4.jar 從 libs 裡刪掉 此 library 的運作模式在想要掃 QR code 的時候使用 ZXScanHelper.scan() 方法，此時 DecodeHandler.handleMessage() 會不斷地被呼叫，decode成功了之後會呼叫 CaptureActivity.handleDecode()，可以在這邊對 decode 之後的結果做篩選，最後可以在我們自己 override 的 onActivityResult() 裡取得解碼後的結果 解決問題：掃描時相機畫面會變成橫的第一步：刪掉強制轉為 landscape 的 code CaptureActivity.java12345678910111213141516171819202122232425262728@Overridepublic void onCreate(Bundle icicle){ super.onCreate(icicle); // 註解(或刪)掉下面這段就不會強迫在掃QR code時用landscape了// if (android.os.Build.VERSION.SDK_INT &lt; 8 || ZXScanHelper.isBlockCameraRotation())// {// setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);// } Window window = getWindow(); window.addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON); setContentView(ZXScanHelper.getCustomScanLayout() &gt; 0 ? ZXScanHelper.getCustomScanLayout() : R.layout.capture); hasSurface = false; inactivityTimer = new InactivityTimer(this); beepManager = new BeepManager(this); if (ZXScanHelper.getUserCallback() != null) { ZXScanHelper.getUserCallback().onScannerActivityCreated(this); }} 第二步：設定 camera 的 orientation，不然在 CaptureActivity 為 portrait 的情況下 camera 會是 landscape CameraManager.java - 加上 forceSetCameraOrientation()123456789101112131415161718192021/** * Opens the camera driver and initializes the hardware parameters. * * @param holder The surface object which the camera will draw preview frames into. * @throws IOException Indicates the camera driver failed to open. */public synchronized void openDriver(SurfaceHolder holder) throws IOException{ // ...省略 try { configManager.setDesiredCameraParameters(theCamera); forceSetCameraOrientation(); // 把相機畫面的 orientation 設為跟 CaptureActivity 一樣 } catch (RuntimeException re) { // ...省略 }} 小提醒：GitHub上的說明在 android:configChanges 少了 screenSize，記得加上 (target API level &gt;= 13的話要加，所以應該幾乎都需要加吧) AndroidManifest.xml1234567&lt;activity android:name=\"com.google.zxing.client.android.CaptureActivity\" android:clearTaskOnLaunch=\"true\" android:stateNotNeeded=\"true\" android:configChanges=\"orientation|keyboardHidden|screenSize\" android:theme=\"@android:style/Theme.NoTitleBar.Fullscreen\" android:windowSoftInputMode=\"stateAlwaysHidden\"&gt;&lt;/activity&gt; 解決問題：改為可以連續掃描多個 QR code第一步：設定 ZXUserCallback，實作 onCodeRead() 方法如 GitHub 頁面所說，呼叫 ZXScanHelper.scan() 之前先呼叫ZXScanHelper.setUserCallback(ZXUserCallback cb)，把過濾邏輯寫在 onCodeRead() 裡 第二步：在 CaptureActivity.handleDecode() 裡增加判斷邏輯，掃到不合格的 QR code 之後要 callrestartPreviewAfterDelay(long delayMS) 重新掃描 CaptureActivity.java123456789101112131415161718192021222324252627/** * A valid barcode has been found, so give an indication of success and show the results. * * @param rawResult The contents of the barcode. * @param barcode A greyscale bitmap of the camera data which was decoded. */public void handleDecode(Result rawResult, Bitmap barcode){ // ...省略 boolean accept = rawResult != null; if (accept &amp;&amp; ZXScanHelper.getUserCallback() != null) { accept = ZXScanHelper.getUserCallback().onCodeRead(rawResult.getText()); } if (accept) { handleDecodeExternally(rawResult, barcode); } else { // 掃到不符合條件的 QR code // do something you want, ex: show a toast restartPreviewAfterDelay(300L); }} 這樣就大功告成囉！","link":"/android-multi-qr-code/"},{"title":"Balanced Binary Tree","text":"題目 做法一思路： 依照 height-balanced 的定義，需要符合每個node 的左右子樹高度差都不大於 1 假設有個 function height 可以回傳 node 的 height 先不實作內容 使用這個 height 完成 isBalanced 實作 height 的內容 Python3 solution: 123456789101112131415161718192021# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef isBalanced(self, root: Optional[TreeNode]) -&gt; bool: def height(node): if not node: # 終止條件 return 0 lh = height(node.left) rh = height(node.right) return max(lh, rh) + 1 if not root: # 終止條件 return True lh = height(root.left) rh = height(root.right) # 即使左右子樹高度差不大於一，子樹本身還是有可能是不平衡的，所以要再加上後面的 `isBalanced` 判斷 return abs(lh - rh) &lt;= 1 and self.isBalanced(root.left) and self.isBalanced(root.right) 假設有 n 個 node, 樹的高度為 h 時間複雜度：O(n^2) isBalanced 除了呼叫自己之外的複雜度為 O(n) 呼叫了 n - 1 次 height 每個節點都呼叫了一次 isBalanced 空間複雜度：O(h) 因為遞迴的呼叫有 DFS 的特性，會從子節點一直呼叫到最下面的葉子節點，所以需要把那些 function calls 放進 stack 裡，等到葉子節點的呼叫到了再一一拿出來執行。因此 stack 的大小需等於呼叫的次數，也就是由根節點走到葉子節點需經過幾個點，即這棵樹的高度 只需考慮一次遞迴呼叫所需空間，不需考慮全部遞迴呼叫 (譬如在 function 裡呼叫了自己兩次)，因為程式同時只會處理一個遞迴呼叫 做法二思路： 有沒有辦法優化上面做法的時間複雜度呢？因為上面在算高度的時候就已經會算出每個節點的左右子樹的高度了，此時就可以順便看看是否平衡，不用等到最後再遞迴呼叫 isBalanced 增加複雜度 Python3 solution: 12345678910111213def isBalanced(self, root: Optional[TreeNode]) -&gt; bool: self.balanced = True def height(node): if not node: return 0 lh = height(node.left) rh = height(node.right) if abs(lh - rh) &gt; 1: self.balanced = False return max(lh, rh) + 1 height(root) return self.balanced 假設有 n 個 node, 樹的高度為 h 時間複雜度：O(n) 每個節點都做過一次 height 空間複雜度：O(h) 同 做法一 的分析 類似題：Symmetric Tree 用 recursive 方法來解","link":"/balanced-binary-tree/"},{"title":"Binary Tree Inorder Traversal","text":"題目思路 Inorder Traversal: 對任意節點來說，順序為 左子樹 -&gt; 自己 -&gt; 右子樹 可拆解為最小單位動作，即第一點，故使用遞迴 12345678910111213141516171819# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightclass Solution: def inorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]: \"\"\"@return node values with inorder-traversal order\"\"\" # Base case if not root: return [] # Recursive case values = self.inorderTraversal(root.left) # 先取得左子節點所有的 inorder-traversal values values.append(root.val) values.extend(self.inorderTraversal(root.right)) # 最後加上右子節點的所有 inorder-traversal values return values 這個題目使用遞迴是相對直觀的，以下改用 iterative 的方式來解：思路：使用一個 list 當 stack 來放 nodes，只要按照順序放入，再從裡面依序把 node pop() 出來取 value，stack 為空的時候代表已處理完所有的 nodes =&gt; 回傳答案。以下列出主要分解動作： 把 root 和 root 所有的左節點由上到下依序放入 stack，放完後 stack 裡自然會包含左節點跟中間的節點 123while root: stack.append(root) root = root.left 把 node pop() 出來取 value，此時最先被 pop 出來的會是最下面的左節點。可以先參照接下來的程式碼，當 node 為葉子節點時，不會有 node.right，所以下一個迴圈會繼續 pop 出中間的節點 12node = stack.pop()values.append(node.val) 左、中節點處理完後，處理右節點：把右節點當成新的 root，重複前兩步驟 root = node.right 上面一行連同前兩步驟的程式碼 (如下)，用 while True: 包起來 寫終止條件：在 node = stack.pop() 之前判斷 stack 是否還有，如為空代表所有的節點已被遍歷完，故回傳答案 values 123456789101112131415161718192021# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightclass Solution: def inorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]: \"\"\"@return node values with inorder-traversal order\"\"\" if not root: return [] stack, values = [], [] while True: while root: stack.append(root) root = root.left if not stack: return values node = stack.pop() values.append(node.val) root = node.right","link":"/binary-tree-inorder-traversal/"},{"title":"121. Best Time to Buy and Sell Stock","text":"題目思路 最直覺的想法是從頭開始 traverse array，針對每一個 price 都去算一次那個位置之後的所有可能利潤，不過這樣會是兩個巢狀 for-loop，時間複雜度是 O(n^2)，太大了 有沒有辦法只 traverse 一次 array 就好？ 利潤是由買價和賣價得出，知道最低買價和最高賣價就可以得出答案。有辦法設定這兩個變數，然後隨著 array traversal 不斷更新嗎？ 可以把 最高賣價 改成 最大利潤，因為這個才是需回傳的答案 Python 3 solution123456789def maxProfit(self, prices: List[int]) -&gt; int: min_bid = float('inf') max_profit = 0 for price in prices: if price &lt; min_bid: min_bid = price elif price - min_bid &gt; max_profit: max_profit = price - min_bid return max_profit","link":"/best-time-to-buy-and-sell-stock/"},{"title":"Binary Number with Alternating Bits","text":"題目 先想到的是有沒有辦法透過 bitwise operation 來判斷，發現無法 看相鄰位置有沒有一樣的，最直覺就是用字串來判斷 =&gt; 可以利用 Python 的 built-in function bin 來把數字轉為 binary 字串 Python3 solution: 123456def hasAlternatingBits(self, n: int) -&gt; bool: b_str = bin(n)[2:] # 去掉前面的 '0b' for i in range(len(b_str) - 1): if b_str[i] == b_str[i + 1]: return False return True","link":"/binary-number-with-alternating-bits/"},{"title":"Binary Tree Level Order Traversal","text":"題目思路 一次一層很直覺想到廣先搜尋 (BFS)，所以用 iterative 的做法來解 一次迴圈處理一層，並把下一層節點放入 stack 繼續在下次迴圈處理 stack 也是 list of list, 裡面的每個 list 都是一層節點 123456789101112131415161718def levelOrder(self, root: Optional[TreeNode]) -&gt; List[List[int]]: if not root: return [] stack, values = [[root]], [] while stack: level_vals = [] level_nodes = [] nodes = stack.pop() for node in nodes: level_vals.append(node.val) if node.left: level_nodes.append(node.left) if node.right: level_nodes.append(node.right) if level_nodes: stack.append(level_nodes) values.append(level_vals) return values 但假如用遞迴的話怎麼解？Recursive case: 把當下這個節點的 value 放到對應 level index 的 list 中 如果沒有對應的 level index 就加一個空 list 進去 (level_ind 會從 0 開始依序傳入，不會有跳號的情況) 12345try: level = res[level_ind]except IndexError: level = [] res.append(level) 123456789101112131415161718192021def levelOrder(self, root: Optional[TreeNode]) -&gt; List[List[int]]: def put_value(node, level_ind, res): # Base case if not node: return # Recursive case try: level = res[level_ind] except IndexError: level = [] res.append(level) level.append(node.val) put_value(node.left, level_ind + 1, res) put_value(node.right, level_ind + 1, res) if not root: return [] res = [] put_value(root, 0, res) return res","link":"/binary-tree-level-order-traversal/"},{"title":"[Python] list 用 `.extend()` 與 `+=` 的差別","text":"譬如有兩個 list a 和 b，使用 a.extend(b) 和 a += b 有什麼相同或不同？有沒有什麼 general 的 best practice for using one rather than the other? 其實在這個情境下，這兩個用法幾乎一樣。它們都會直接 in-place 的修改 a，把 b 裡面的元素加到 a 的後面 += 會呼叫 list 的 .__iadd__() 來做 in-place 的修改 所以在這個情境下，b 可以是任何 iterable，譬如 [] += {} 會得到 [] 假如用 += 的是 immutable 的 type，Python 發現沒有 .__iadd__()，接著就會呼叫它的 .__add__()，此情況下 a += b 等同於 a = a + b 以下列出少數有差別的地方： += 不能用在 tuple 裡的 list，但 .extend() 可以 雖然說 += 所呼叫的 .__iadd__() 是 in-place 修改，做完後 a 的 reference 還是會一樣，但過程中還是會以某種方式動到 reference，只是最後會有個 reassign 給自己的動作[註1]，所以會有一樣的 reference += 不能用在 non-local variable，但 .extend() 可以 += 不能 chain function call, 但 .extend() 可以 兩者速度依不同情況稍有差異 可參考註1這個 comment 下兩個接續的 comments: comment 1, comment 2 結論可以都用 .extend() 就好，consistency 也是一個重點。對於有差別的部分，一般情況下速度的差異可以忽略，其他的差別都是 .extend() 比較好，而且它在語意上的描述也也更貼切。 參考資料： Concatenating two lists - difference between ‘+=’ and extend() What is the difference between Python’s list methods append and extend? 註1: l1 += l2 and l1.extend(l2) ultimately execute the same code (the list_extend function in listobject.c). The only differences are: 1. += reassigns l1 (to itself for lists, but the reassignment supports immutable types that aren’t the same object after), which makes it illegal if l1 is actually an attribute of an immutable object; for example, t = ([],), t[0] += lst would fail, while t[0].extend(lst) would work. 2. l1 += l2 uses dedicated bytecodes, while l1.extend(l2) uses generalized method dispatch; this makes += faster than extend. Why does += behave unexpectedly on lists?","link":"/diff-between-extend-and-plusequal/"},{"title":"Web Server 與 Application Server 的差別","text":"圖片來源: https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_web_01.pdf 看到 AWS 關於 web application 的 architecture 這張圖之後，不太懂為何 server 要分為兩層，於是就google 了一下，找到一篇不錯的文章。這邊配合AWS的圖做個簡短的summary: Application Server: 專門用來處理 business logic 的，較常見的用法是接受 web server 的 request，執行完 business logic (過程中視需要去 access DB tier)之後把 result 回給 web server Web Server: 專門只處理 HTTP request 與 response，當收到 HTTP request 之後，需要 business logic 的部分就從 application server 取，最後把 result 轉為 HTTP response","link":"/difference-between-web-and-application-server/"},{"title":"438. Find All Anagrams in a String","text":"題目思路：怎麼判斷兩個字串是不是 anagram? 可以把兩個字串都做排序，再看看是否相等，但這樣每次都要多花 O(n) 時間 可以計算每個字母出現的頻率，再看看兩個字串的計算結果是否相等。雖然單獨算也是要 O(n)，但假如搭配 sliding window 移動的時候一個個字母加入計算，就不會有額外的時間複雜度 Python 3 solution123456789101112131415161718192021222324def findAnagrams(self, s: str, p: str) -&gt; List[int]: p_len = len(p) if p_len &gt; len(s): return [] target_freq = defaultdict(int) # Character frequency of possible anagram. # Character frequency of `p`. p_freq = defaultdict(int) for c in p: p_freq[c] += 1 res = [] for i in range(len(s)): # 把超過 p 長度的部分扣掉，維持 window 寬 (想像 window 往右，這邊移掉左邊一格) if i &gt;= p_len: target_freq[s[i - p_len]] -= 1 if target_freq[s[i - p_len]] == 0: del target_freq[s[i - p_len]] # 個數減為 0 的話記得要把整個 key 拿掉，不然不可能會跟 `p_freq` 相等 target_freq[s[i]] += 1 # Frequency 計算：加入當前字元 (`i` 是 sliding window 最右邊的 index) if target_freq == p_freq: res.append(i - p_len + 1) # 加入 sliding window 起始點到答案中 return res P.S.字母頻率計算也可以用 collections.Counter，跟 defaultdict(int) 使用方法一樣，範例： 1234567&gt;&gt;&gt; import collections&gt;&gt;&gt; c = collections.Counter('geeeg')&gt;&gt;&gt; cCounter({'e': 3, 'g': 2})&gt;&gt;&gt; c['t'] += 1&gt;&gt;&gt; cCounter({'e': 3, 'g': 2, 't': 1}) collections.Counter 建構子可以傳入任何 iterable","link":"/find-all-anagrams-in-a-string/"},{"title":"Effective Python Note 2","text":"This article is composed of some notes from book Effective Python. Use @property to define special behavior when attributes are accessed/set on your objects, if necessaryAnother use case is to only specify getter to make that attribute read-only. property_decorator_example.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Movie: def __init__(self): super().__init__() self._rating = 0 self._reviewer_count = 0 # read-only attribute @property def rating(self): \"\"\"Getter for _rating\"\"\" return self._rating @rating.setter def rating(self, value): \"\"\"Setter for _rating\"\"\" if not isinstance(value, int): raise ValueError('Rating must be an integer!') if not (0 &lt;= value &lt;= 10): raise ValueError('Rating must between 0 ~ 10!') self._rating = value self._reviewer_count += 1 @property def reviewer_count(self): return self._reviewer_countmovie = Movie()print('Before rating:', movie.rating)movie.rating = 8print('After rating:', movie.rating)try: movie.rating = 11except ValueError as e: print(str(e))print('Reviewer count:', movie.reviewer_count)try: movie.reviewer_count = 5except AttributeError as e: print(str(e)) &gt;&gt;&gt;Before rating: 0After rating: 8Rating must between 0 ~ 10!Reviewer count: 1can't set attribute Use descriptors for reusable @property methodsIf you want to reuse the logic in @property methods, you have to use a descriptor. The descriptor protocol defines how attribute access is interpreted by the language. Descriptor: an object attribute with “binding behavior”, one whose attribute access has been overridden by methods in the descriptor protocol Descriptor Protocol:descriptor.__get__(self, obj, type=None) -&gt; valuedescriptor.__set__(self, obj, value) -&gt; Nonedescriptor.__delete__(self, obj) -&gt; None descriptor_example.py123456789101112131415161718192021222324252627282930313233343536373839404142from weakref import WeakKeyDictionaryclass Grade: def __init__(self): self._instance_value_map = WeakKeyDictionary() def __get__(self, instance, owner): if instance is None: return self return self._instance_value_map.get(instance, 0) def __set__(self, instance, value): if not (0 &lt;= value &lt;= 100): raise ValueError('Grade must be between 0 and 100') self._instance_value_map[instance] = valueclass Exam: # Descriptors only works with class attributes math_grade = Grade() writing_grade = Grade() science_grade = Grade()first_exam = Exam()try: first_exam.writing_grade = 120except ValueError as e: print(str(e))first_exam.writing_grade = 82second_exam = Exam()second_exam.writing_grade = 75print('First writing grade:', first_exam.writing_grade)print('Second writing grade:', second_exam.writing_grade)&gt;&gt;&gt;Grade must be between 0 and 100First writing grade: 82Second writing grade: 75 Under the hood When you assign a property as in line 28, it will be interpreted as: Exam.__dict__['writing_grade'].__set__(first_exam, 120)When you retrieve a property as in line 35, first_exam.writing_grade will be interpreted as: Exam.__dict__['writing_grade'].__get__(first_exam, Exam) What drives this behavior is the __getattribute__ method of object. In short, when an Exam instance doesn’t have an attribute named writing_grade, Python will fall back to the Exam class’s attribute instead. If this class attribute is an object that has __get__ and __set__ methods, Python will assume you want to follow the descriptor protocol. Note: Descriptor protocol only works with class attributes, so don’t use it with instance attributes. It’s reasonable to keep object behavior in the class definition. Otherwise, the mere act of assigning a descriptor to an instance attribute would change the object behavior. (more discussion on StackOverflow) Why using _instance_value_map?A single Grade instance is shared across all Exam instances for the class attribute writing_grade, so we need the Grade class to keep track of its value for each unique Exam instance. Why using WeakKeyDictionary instead of just {}?Use {} will leak memory. The _instance_value_map will hold a reference to every instance of Exam ever passed to __set__ over the lifetime of the program, preventing cleanup by the garbage collector. WeakKeyDictionary will remove Exam instances from its set of keys when the runtime knows it’s holding the instance’s last remaining reference in the program. Annotate class attributes with metaclassesContinue with the above descriptor section. You can avoid both memory leaks and the weakref module by using metaclasses along with descriptors. descriptor_with_metaclass_example.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Grade: def __init__(self): self.internal_attr_name = None # will be assigned by the metaclass def __get__(self, instance, owner): if instance is None: return self return getattr(instance, self.internal_attr_name, 0) def __set__(self, instance, value): if not (0 &lt;= value &lt;= 100): raise ValueError('Grade must be between 0 and 100') setattr(instance, self.internal_attr_name, value)class Meta(type): def __new__(meta_cls, name, bases, class_dict): for key, value in class_dict.items(): if isinstance(value, Grade): value.internal_attr_name = f'_{key}' return type.__new__(meta_cls, name, bases, class_dict)class BaseExam(metaclass=Meta): passclass Exam(BaseExam): # Descriptors only works with class attributes math_grade = Grade() writing_grade = Grade() science_grade = Grade()first_exam = Exam()try: first_exam.writing_grade = 120except ValueError as e: print(str(e))first_exam.writing_grade = 82second_exam = Exam()second_exam.writing_grade = 75print('First writing grade:', first_exam.writing_grade)print('Second writing grade:', second_exam.writing_grade)&gt;&gt;&gt;Grade must be between 0 and 100First writing grade: 82Second writing grade: 75 The __new__ method of metaclassesIt’s run immediately after the class statement’s entire body has been processed. If using print(meta_cls, name, bases, class_dict, sep='\\n', end='\\n\\n') in the first line of __new__ in the above program: 12345678&lt;class '__main__.Meta'&gt;BaseExam(){'__module__': '__main__', '__qualname__': 'BaseExam'}&lt;class '__main__.Meta'&gt;Exam(&lt;class '__main__.BaseExam'&gt;,){'__module__': '__main__', '__qualname__': 'Exam', 'math_grade': &lt;__main__.Grade object at 0x1021855c0&gt;, 'writing_grade': &lt;__main__.Grade object at 0x1021855f8&gt;, 'science_grade': &lt;__main__.Grade object at 0x102185630&gt;} Note: Another use case of metaclasses is to validate class attributes of subclasses. We can do the validation in the __new__ method and detect improper subclasses before their usage.","link":"/effective-python-note-2/"},{"title":"Effective Python Note","text":"This article is composed of some notes from book Effective Python. Scope ResolutionPython’s scope resolution follows the order below: current function enclosing scopes: like a outer function enclosing the current function global scope build-in scope Sample code12345678910111213141516171819202122232425global_var = 'global value'def outer(): enclosing_var = 'enclosing value' enclosing_var_2 = 'enclosing value 2' def inner(): local_var = 'local value' print('local_var:', local_var) print('enclosing_var:', enclosing_var) enclosing_var_2 = 'changed enclosing value 2' # a new variable definition inner() print('glocal_var:', global_var) print('enclosing_var_2:', enclosing_var_2)outer()&gt;&gt;&gt;local_var: local valueenclosing_var: enclosing valueglocal_var: global valueenclosing_var_2: enclosing value 2 Note that the assignment of enclosing_var_2 in function inner is actually a new variable definition, because enclosing_var_2 is not in the current scope. It’s designed to prevent local variables polluting its outer scopes. So we can see value of enclosing_var_2 doesn’t change. GeneratorIt’s a function using yield instead of return. Return an iterator when it gets called. Every call of next with that iterator will result in code execution to the next yield and the iterator will return what’s passed to the yield. simple_generator.py12345678910111213141516def gen(): for i in range(3): yield iit = gen()print(next(it))print(next(it))print(next(it))&gt;&gt;&gt;012 Whenever you want to use a function to compose a list, you can consider using a generator instead, which is a cleaner way. generator_simple_use_case.py12345678910111213141516171819def create_results(num): results = [] for i in range(num): results.append(i * 10) return resultsdef results_gen(num): for i in range(num): yield i * 10print('Results from create_results:', create_results(3))print('Results from results_gen:', list(results_gen(3)))&gt;&gt;&gt;Results from create_results: [0, 10, 20]Results from results_gen: [0, 10, 20] A pitfallIf an iterator is used up (a StopIteration exception has been thrown), you will get no results for iterating it again. And there will be no exceptions. generator_pitfall.py1234567891011121314151617181920212223def results_gen(number): for i in range(number): yield i * 10def normalize(numbers): total = sum(numbers) # `sum` will use up iterator `numbers` result = [] for value in numbers: # no things to iterate in `numbers` percent = value / total * 100 result.append(percent) return resultit = results_gen(3)percentages = normalize(it)print('percentages:', percentages)&gt;&gt;&gt;percentages: [] Solutions Copy content of the iterator to a list and use the list afterward. Pass a lambda instead of numbers which returns a new generator on every call. Implement iterator protocol. That is, implement __iter__ as a generator. generator_pitfall_sol_3.py12345678910111213141516class ResultsContainer: def __init__(self, number): self.number = number def __iter__(self): for i in range(self.number): yield i * 10results_container = ResultsContainer(3)percentages = normalize(results_container)print('percentages:', percentages)&gt;&gt;&gt;percentages: [0.0, 33.33333333333333, 66.66666666666666] Each traversal of the results_container object will cause it to return a new iterator (calling __iter__ every time), so there won’t be this issue. Single asterisk used in function definition and function call*numbers is called optional positional arguments. It indicates that this function can take zero or more than one positional arguments starting from that position. It should be put after all positional arguments in a function definition. It will pack those arguments into one tuple to use in the function. * before nums will unpack any iterable nums so that print_numbers(0, 5, *nums) will be print_numbers(0, 5, 1, 2, 3) single_asterisk_with_function.py123456789101112131415def print_numbers(first_num, *numbers): print('first_num:', first_num) print('numbers:', numbers)nums = [1, 2, 3]print_numbers(0, 5, *nums)print_numbers(6)&gt;&gt;&gt;first_num: 0numbers: (5, 1, 2, 3)first_num: 6numbers: () Use __call__ special method to turn class instances into functionsIf we define __call__ in our class, we can turn the class instances into functions. Each call on the instance will invoke calling of its __call__ . So, when there is a need for a function to preserve some state, you can consider using a class with __call__ method. It’s more readable than a stateful closure. callable_class_example.py1234567891011121314151617181920212223242526272829303132333435363738from collections import defaultdictclass MissingCounter: \"\"\" Provide default color count and record how many missing colors when adding increments. \"\"\" def __init__(self): self.added = 0 def __call__(self, *args, **kwargs): self.added += 1 return 0 missing_counter = MissingCounter()init_dict = { 'green': 12, 'blue': 3}color_count_map = defaultdict(missing_counter, init_dict)increments = [ ('red', 5), ('blue', 17), ('orange', 9)]for color, amount in increments: color_count_map[color] += amountprint('missing_counter is callable:', callable(missing_counter))print('Missing colors added count:', missing_counter.added)&gt;&gt;&gt;missing_counter is callable: TrueMissing colors added count: 2","link":"/effective-python-note/"},{"title":"733. Flood Fill","text":"題目紀錄一下一開始的思路，檢討錯誤，再整理最後的答案。一開始的想法： 這應該可以分解成最小可重複動作，用遞迴解看看 覺得可以用原本的 method 當遞迴函式，把 image, color 照樣傳入，sr, sc 為該點的座標 最小可重複動作：從當下這點擴散到周圍四個點 Wrong solution at first1234567891011121314151617181920212223242526272829def floodFill(self, image: List[List[int]], sr: int, sc: int, color: int) -&gt; List[List[int]]: self_color = image[sr][sc] m = len(image) n = len(image[0]) # Base case if sr &lt; 0 or sr &gt;= m or sc &lt; 0 or sc &gt;= n or color == self_color: return image l_color = image[sr - 1][sc] r_color = image[sr + 1][sc] u_color = image[sr][sc + 1] d_color = image[sr][sc - 1] if self_color not in (l_color, r_color, u_color, d_color): image[sr][sc] = color return image # Recursive case if l_color == self_color: image[sr][sc] = color self.floodFill(image, sr - 1, sc, color) if r_color == self_color: image[sr][sc] = color self.floodFill(image, sr + 1, sc, color) if u_color == self_color: image[sr][sc] = color self.floodFill(image, sr, sc + 1, color) if d_color == self_color: image[sr][sc] = color self.floodFill(image, sr, sc - 1, color) 結果發生 index out of bound error (舉例，當 sr == m - 1 時，再用 image[sr + 1] 就會遇到) 檢討： 會用到 image[sr + 1] 是為了要取到鄰近的顏色來判斷是不是應該去 flood，而那些判斷只是為了決定是否要執行遞迴呼叫 =&gt; 判斷是否該執行遞迴呼叫應該直接在該遞迴函式的 base case 裡做判斷 不去取顏色自然就不會遇到這個錯誤 改成在 base case 的判斷 我這個點的顏色是不是跟起點的顏色一樣 中間這段沒必要，此情境已包含於那些遞迴呼叫裡 123if self_color not in (l_color, r_color, u_color, d_color): image[sr][sc] = color return image 可以把題目的 color 參數名改為 new_color，增加可讀性 可以另外用一個 inner function 來當遞迴函式，因為實際會傳不一樣參數的只有座標，另兩個其實可以不用傳入，另外用一個 inner function 可以讓程式更簡潔易讀 根據上面的檢討，修改後的答案如下： Python 3 solution - DFS123456789101112131415161718192021def floodFill(self, image: List[List[int]], sr: int, sc: int, new_color: int) -&gt; List[List[int]]: ori_color = image[sr][sc] m = len(image) n = len(image[0]) def flood(row, col): # Base case if row &lt; 0 or row &gt;= m or col &lt; 0 or col &gt;= n: return if image[row][col] != ori_color or image[row][col] == new_color: return image[row][col] = new_color # Recursive case flood(row + 1, col) flood(row - 1, col) flood(row, col + 1) flood(row, col - 1) flood(sr, sc) return image 記得要先把起點的顏色記到變數裡，而不是在 base case 的判斷裡直接用 image[sr][sc] 來取，因為起點的顏色在經過第一次 flood 呼叫後就變了 base case 裡這個判斷 image[row][col] == new_color，它主要是在看假如這個點已經 flood 過了，就直接 return，但還有一種情形：沒 flood 過，這個點本來就是 new_color。假如是這種情況，又再細分為以下兩個情形： ori_color != new_color: 假如是這種情況，在前面的 image[row][col] != ori_color 就會滿足而 return 了 ori_color == new_color: 此時也應該 return，因為假如是這樣，那本來整個 image 就不會因為 floodFill 而變 上面的遞迴解法是屬於 DFS (Depth-First Search)，假如用 BFS (Breadth-First Search) 來解呢？假如已經用 DFS 解過了，那 BFS 應該可以依循同樣的思考邏輯很快寫出來，只需調整一下架構： 先過濾掉不需繼續做的情況 準備一個 stack，放入起始情況的條件 只要 stack 裡有東西，就做最小可重複動作 終止條件對應到上面的 base case，要繼續檢查的部分對應到上面的 recursive case Python 3 solution - BFS12345678910111213141516171819202122def floodFill(self, image: List[List[int]], sr: int, sc: int, new_color: int) -&gt; List[List[int]]: ori_color = image[sr][sc] if new_color == ori_color: return image stack = [(sr, sc)] m = len(image) n = len(image[0]) while stack: row, col = stack.pop() # 終止條件 if row &lt; 0 or row &gt;= m or col &lt; 0 or col &gt;= n: continue if image[row][col] != ori_color or image[row][col] == new_color: continue image[row][col] = new_color # 要繼續檢查的部分 stack.extend([(row + 1, col), (row - 1, col), (row, col + 1), (row, col - 1)]) return image","link":"/flood-fill/"},{"title":"House Robber II","text":"題目思路 跟 House Robber 很像，只差在房子的排列變成頭尾相連，有沒有辦法把這題拆解，變成能用上第一版 House Robber 的解題方法？譬如把環形變回直排？ 變成環形之後多出來的限制讓我們可以把這題分成以下三種情況： 搶第一個、不搶最後一個：加入第三種情況，等同於可以視為直排，但只考慮到倒數第二個 不搶第一個、搶最後一個：加入第三種情況，等同於可以視為直排，但從第二個開始考慮 第一個和最後一個都不搶：可與前兩種情況合併 最後把以上三種情況合併為粗體的兩種情況，轉為第一版 House Robber 問題，接下來只需取兩種情況錢比較多的就是答案 因為現在需多考慮起始 index，我們把第一版解法的遞迴函式改為多傳入起始 index，並同樣用 @cache 避免同樣的 inner_rob(i, j) 重複計算 Base case 寫法： 考慮一開始 j 比 i 大的情況，一路因為 inner_rob(i, j - 1), inner_rob(i, j - 2) 而減少的情況： j == i + 2 時：下兩個遞迴節點為 inner_rob(i, i + 1), inner_rob(i, i) j == i + 1 時： 下兩個遞迴節點為 inner_rob(i, i), inner_rob(i, i - 1) 此時可以寫出 base case 的兩種情況 j == i, j &lt; i，寫完後將 inner_rob(i, j) 代入 j == i + 1 驗算看看是否正確 考慮一開始 j == i 的情況，代入驗算看看是否正確 考慮一開始 j &lt; i 的情況，也就是 len(nums) == 1 時： 此時得出的答案為 0，是錯的，所以 base case 需多考慮這種情況，加入 len(nums) == 1 時的判斷處理 取錢比較多的情況即為答案：return max(inner_rob(0, len(nums) - 2), inner_rob(1, len(nums) - 1)) Python3 solution: 12345678910111213141516def rob(self, nums: List[int]) -&gt; int: @cache def inner_rob(i, j): \"\"\"@return 由 index i 搶到 j 可得的最大收穫\"\"\" # Base case if len(nums) == 1: return nums[0] if j == i: return nums[j] if j &lt; i: return 0 # Recursive case return max(inner_rob(i, j - 1), nums[j] + inner_rob(i, j - 2)) return max(inner_rob(0, len(nums) - 2), inner_rob(1, len(nums) - 1)) 如果不用 @cache: 12345678910111213141516171819def rob(self, nums: List[int]) -&gt; int: l = len(nums) memo = [[None] * l for _ in range(l)] def inner_rob(i, j): \"\"\"@return 由 index i 搶到 j 可得的最大收穫\"\"\" if len(nums) == 1: return nums[0] if i == j: return nums[j] if j &lt; i: return 0 if memo[i][j] is not None: return memo[i][j] memo[i][j] = max(inner_rob(i, j - 1), nums[j] + inner_rob(i, j - 2)) return memo[i][j] return max(inner_rob(0, len(nums) - 2), inner_rob(1, len(nums) - 1))","link":"/house-robber-ii/"},{"title":"House Robber","text":"題目思路 可以把得出答案的過程拆解為最小可重複步驟，用遞迴來解 Recursive case: 假設 index 為 i，由 index 0 搶到 i 可得的最大收穫為 inner_rob(i)。在位置 i, 可選擇搶或不搶： 不搶：最大收穫跟前一個點一樣，為 inner_rob(i - 1) 搶：代表前一個點一定是不搶，所以最大收穫為這個點的 money nums[i] 再加上前前個點的最大收穫 inner_rob(i - 2) 所以 inner_rob(i) 為以上兩種情況取較大的那個 Base case (終止條件)：i &lt; 0 因為這個遞迴解的時間複雜度最差為 O(2^n)，必須降低，我們可以把計算過的 inner_rob(i) 使用 @cache 將 function 回傳 cache 起來，避免同樣的 inner_rob(i) 重複計算 Python3 solution: 12345678def rob(self, nums: List[int]) -&gt; int: @cache def inner_rob(i): \"\"\"@return 由 index 0 搶到 i 可得的最大收穫\"\"\" if i &lt; 0: return 0 return max(inner_rob(i - 1), nums[i] + inner_rob(i - 2)) return inner_rob(len(nums) - 1) 時間複雜度：O(n) 因為有記憶，每個點只會計算一次，共有 n 個點 空間複雜度：O(n) cache 需要的空間為 n，遞迴的最大深度也是 n 以上，如果不用 @cache 的話： 12345678910def rob(self, nums: List[int]) -&gt; int: memo = [None] * len(nums) def inner_rob(i): if i &lt; 0: return 0 if memo[i] is not None: return memo[i] memo[i] = max(inner_rob(i - 1), nums[i] + inner_rob(i - 2)) return memo[i] return inner_rob(len(nums) - 1)","link":"/house-robber/"},{"title":"簡單統整 JWT 相對於傳統 Session 驗證的好處","text":"Server 不用存 Session 只有在 Client 拿新 JWT 時才需要跟 DB 溝通 Clent 拿的時機：JWT 到期或第一次拿 為何不需跟 DB 溝通？ 因為 JWT 裡已有所需資訊 但假如業務需求需要另外取敏感資訊的話還是需要碰 DB 參考","link":"/jwt-digest/"},{"title":"Isomorphic Strings","text":"題目這題看似不難，但第一次的做法錯了，第一次的程式碼如下，想法是用 mapping 組一個新字串 t2，假如跟 t 相同就 return True Python 3 wrong solution: 12345678def isIsomorphic(self, s: str, t: str) -&gt; bool: d = {} for i in range(len(s)): d[s[i]] = t[i] t2 = '' for c in s: t2 += d[c] return t == t2 測出錯誤的 input: 12s = \"badc\"t = \"baba\" 錯誤點在於沒有檢查這個條件：No two characters may map to the same character 檢討如下： 寫完要 run 之前應該最後 check 一次是否有滿足題目提到的所有條件 以這題來說，比較好的做法是一個個 check 每個 character 這樣只需跑一次 for-loop，不需要再跑第二次組一個新字串 每個 character 都 check 就不會漏掉上面那個條件 修正解法如下Python 3 solution: 1234567891011def isIsomorphic(self, s: str, t: str) -&gt; bool: mapping = {} for i in range(len(s)): if s[i] not in mapping: if t[i] in mapping.values(): # 一個 t 字母同時對應到兩個 s 字母 return False mapping[s[i]] = t[i] else: if mapping[s[i]] != t[i]: # 一個 s 字母同時對應到兩個 t 字母 return False return True","link":"/isomorphic-strings/"},{"title":"142. Linked List Cycle II","text":"題目思路：最直覺的作法就是從頭開始沿著 next 一直走，然後用一個 set 來存放走過的 node，如果再次走到已走過的 node 就是 cycle 起點 Python 3 solution1234567891011121314# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Nonedef detectCycle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: visited = set() curr = head while curr: if curr in visited: return curr memo.add(curr) curr = curr.next return 平均時間複雜度：O(n) 因為 in 和 add 對於 set 來說都是 O(1)，所以 while 迴圈內每次執行的複雜度為 O(1) 平均空間複雜度：O(n) 如果想讓空間複雜度是 O(1) 呢？此時必須使用 Floyd’s Cycle Detection algorithm，但假如之前沒看過這個演算法，怎樣的思路最有可能導向用它來解呢？此演算法背後的原理又為何？ Linked list 不要動用額外空間最直覺的解題方式，就是單純靠指標的移動來解，而這題顯然無法靠單一指標做到。那雙指標做得到嗎？ 假如用快慢雙指標同時從起點出發的話，他們會在 cycle 裡交會，而我們要知道 cycle 起點的唯一方法，就是想辦法讓兩個指標在 cycle 起點交會，如何做到？ 快指標走的速度是慢指標的兩倍 想讓指標在 cycle 起點交會，首先必須知道各段距離之間的關聯，我們可以畫個圖，把 起點、cycle 起點、cycle 裡的交會點 先標示出來，利用我們目前已知的條件：在 cycle 裡交會時，快指標走的距離是慢指標的兩倍 來列出方程式，釐清各個距離之間的關係。下面這個影片從 6:37 開始把推導過程講得很清楚 不過影片講解的最後有個地方我覺得可以再多講一下，影片裡一開始假設快指標比慢指標多走了一圈 cycle，最後放寬這個限制，因為快指標有可能多走超過一圈 cycle，此時等式覺得這樣改寫比較容易懂： 1232 * slow = fast2 * (p + c - x) = p + 2c - x + nc # n 可為 0 或正整數，代表快指標除了已經多走了一圈之外，又再多走的圈數p = x + nc 最後的 p = x + nc 代表：就算走完 x 還無法會合，只要再多走 n 圈還是會相會，而且一定還是會在 cycle 起始點會合 如影片裡所說，當快慢指標會合後，把其中一個指標放回原點，再讓兩個指標同速往前，他們的交會點就會是 cycle 起點 雖然講完之後感覺程式寫起來蠻簡單，但我一開始還是犯了個小錯誤，一開始寫法如下： Wrong solution1234567891011121314151617181920# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Nonedef detectCycle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: fast = slow = head while fast and fast.next: slow = slow.next fast = fast.next.next if slow is fast: # slow 與 fast 交會 break else: return node = head while slow: slow = slow.next node = node.next if slow is node: return node 有發現錯在哪嗎？當 case 是這張圖 的時候，我回傳的 node 是 val 為 2 的 node 而非正確答案。問題出在我沒有考慮到一個情境：當快慢指標會合之後，那個點有可能已經是 cycle 起點了，而當這個起點又剛好是 head 的時候，上面的程式就會出錯 我錯在假設在 fast &amp; slow 第一次相會之後，slow &amp; node 兩個指標一定要動才會相會，但當 cycle 起點也是 head 的時候，他們不一定要動就可能相會。所以要改的部分就是第 16 行之後，因為它們一定會相遇，while 條件可以改成 while node is not slow:，只要他們還沒相遇就做移動，直到相遇為止 修改後的正確答案12345678910111213141516171819# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Nonedef detectCycle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: fast = slow = head while fast and fast.next: slow = slow.next fast = fast.next.next if slow is fast: # slow 與 fast 交會 break else: # fast 走到底了兩個都還沒交會 return node = head while node is not slow: slow = slow.next node = node.next return node 這邊稍微提一下 Python 的 while-else，它是別的語言比較沒有的用法，但有時候還蠻好用的。else 的內容會在 while 正常結束時被執行，也就是當 while 被 break 之後，是不會執行 else 內容的。所以這邊的用法就是： 當 slow 與 fast 交會，就繼續往下做 當 fast 走到底了兩個都還沒交會，就是沒有 cycle，此時直接 return 如果不用 while-else，就必須在 while 後面寫 12if not fast or not fast.next: return 相對來說比較沒那麼簡潔","link":"/linked-list-cycle-ii/"},{"title":"409. Longest Palindrome","text":"題目思路 怎麼判斷一個 string 是否為 palindrome？ (x) 做一個倒過來的 string 看看兩個是否相等 需要 O(n) 時間複雜度，太長了，因為你必須對所有的字串組合做測試 (o) Palindrome 一定是由偶數個數的字母組成，頂多再加上一組奇數個數的字母 先用 dict 記錄每個 character 的個數，再利用計算完成的 dict 來算出答案 想完之後覺得應該蠻簡單，結果寫完送出…… Wrong Answer! Wrong Answer1234567891011121314def longestPalindrome(self, s: str) -&gt; int: # Build dict for characters. d = defaultdict(int) for c in s: d[c] += 1 max_odd = 0 count = 0 for freq in d.values(): if freq % 2 == 0: count += freq elif freq &gt; max_odd: max_odd = freq return count + max_odd 錯誤之處在於我除了把偶數個數的字母納入之外，只挑了一個出現最多次的奇數字母納入答案，忘了其實奇數個數的字母可以拆成偶數… 所以會少算到很多 但這樣做完之後，要記得假如裡面有奇數次的字母，最後的答案要再加一 Python 3 solution：調整後的正確答案123456789101112131415def longestPalindrome(self, s: str) -&gt; int: # Build dict for character count. d = defaultdict(int) for c in s: d[c] += 1 odd_complement = False count = 0 for freq in d.values(): if freq % 2 == 0: count += freq else: odd_complement = True count += freq - 1 return count + odd_complement 最後提一下那個 count + odd_complement，Python 在遇到整數和布林值相加的時候，會把布林值轉為整數再相加 (True =&gt; 1, False =&gt; 0)，覺得是還不錯的 feature 浮點數和布林值相加也類似，會把布林值作轉換後再相加 (True =&gt; 1.0, False =&gt; 0.0)","link":"/longest-palindrome/"},{"title":"Merge Two Sorted Lists","text":"題目思路： 因為要做一個 linked list，可以用 while 在每次迴圈都接一個 node 出來 先設 while True:，等寫迴圈內容時再來確定 while 可繼續執行的條件 寫第一 part (如下) 後發現，while 條件需要 l1 and l2 123456if l1.val &gt; l2.val: curr.next = l2 l2 = l2.nextelse: curr.next = l1 l1 = l1.next post processing: 跳出迴圈後的情形是 l1, l2 其中有一個是 None 或兩個都是 None，此時就把目標 linked list 接上那個不是 None 的即可 Python3 solution: 12345678910111213def mergeTwoLists(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]: dummy_head = ListNode() # 需有一個 dummy_head 可以在最後回傳答案時使用 curr = dummy_head # 也要有個 curr 可以在每次迴圈中跟著移動 while l1 and l2: if l1.val &gt; l2.val: curr.next = l2 l2 = l2.next else: curr.next = l1 l1 = l1.next curr = curr.next curr.next = l1 or l2 # post processing return dummy_head.next P.S. 有些思路跟 Add Two Numbers 重複，這篇就不多寫了","link":"/merge-two-sorted-lists/"},{"title":"Merge Two Binary Trees","text":"題目 做法一：recursive - DFS 找出最小的可重複動作：merge 兩個 nodes 題目給的 method 就可以用來做遞迴 假設 mergeTrees 已完成，實作此最小可重複動作 1234root1.val += root2.valroot1.left = self.mergeTrees(root1.left, root2.left)root1.right = self.mergeTrees(root1.right, root2.right)return root1 寫出遞迴的終止條件 12if not root1 or not root2: return root1 or root2 Python3 solution: 12345678910111213# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef mergeTrees(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -&gt; Optional[TreeNode]: if not root1 or not root2: return root1 or root2 root1.val += root2.val root1.left = self.mergeTrees(root1.left, root2.left) root1.right = self.mergeTrees(root1.right, root2.right) return root1 假設兩棵樹有較少節點的那顆有 n 個節點 時間複雜度：O(n) 空間複雜度：n 個節點那棵樹的深度 最差情況是 O(n), 平均為 O(log n) 做法二：iterative - BFS 準備一個 stack 來放待 merge 的 node pairs 一次從裡面拿一個 pair 出來 merge, 同時也把該 merge 的子節點 pair 丟進去。一直做到 stack 裡面沒東西為止 因為這邊是 merge 到 root1, 故最後回傳 root1 注意不要回傳到 p, 而是應該回傳當初的根節點 root1 Python3 solution: 12345678910111213141516171819202122# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef mergeTrees(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -&gt; Optional[TreeNode]: if not root1 or not root2: return root1 or root2 stack = [(root1, root2)] while stack: p, q = stack.pop() # 使用暫時的變數 p, q 來操作節點 merge p.val += q.val if not p.left and q.left: p.left = q.left elif p.left and q.left: stack.append((p.left, q.left)) if not p.right and q.right: p.right = q.right elif p.right and q.right: stack.append((p.right, q.right)) return root1 假設兩棵樹有較少節點的那顆有 n 個節點 時間複雜度：O(n) stack 裡會有 n 個 pairs, 所以會做 n 次 空間複雜度：O(n) 需要大小為 n 的 stack","link":"/merge-two-binary-trees/"},{"title":"用 pipenv 管理 requirements 搭配 docker-compose local 開發","text":"Local 開發是跑在 Docker 的虛擬環境裡，所以 Pipenv 產生的虛擬環境只是用來裝套件產生 Pipfile.lock 而已 用 pipenv 就不用自己寫 requirements.txt，不但可以自動安裝最新版的套件，而且可以很輕鬆的固定住對應 sub-packages 的版本 想一次更新所有套件也很容易 步驟：(以裝一個 package 為例) pip install --user pipenv 裝完後 command line 找不到 pipenv 的需把對應資料夾加入 PATH cd 到專案資料夾 pipenv install {target-package} 假如原本沒有 virtual environment，pipenv 會先幫你產生一個基於這個資料夾的 virtual environment 假如上層資料夾有 Pipfile，pipenv 會直接用那個 Pipfile 的 virtual environment，不會產生新的 這是因為 pipenv 的虛擬環境是 project base 的，所以你可以在一個 Django project 裡的任何一個資料夾執行 pipenv 都可以用到這個 project 的虛擬環境 而且正常情況下不會有 Django project 裡還有 Django project 的情況，所以不需要在上層已有 Pipfile 的情況下，又在目前資料夾產生 Pipfile 這邊不要指定版號，pipenv 就會安裝最新版 pipenv 會產生 Pipfile 和 Pipfile.lock, 後者有記錄這個 package 和 sub-packages 的固定版號 pipenv lock -r &gt; requirements.txt 將 Pipfile.lock 輸出為 requirements.txt 格式 接著就可以在 Dockerfile 裡直接用這個 requirements.txt 啦 如果要開新的 Django project: cd {你想要 project 資料夾放的位置} mkdir {project-name}; cd {project-name} pipenv install Django pipenv run django-admin startproject {project-name} . .: 要把 manage.py 放在當前資料夾 之後假如要把 requirements.txt 裡所有的 top-level 套件都更新的話: pipenv update 這個我自己沒試過，不過看文件應該是用這指令 重新輸出 requirements.txt 有看到另一種做法是可以不用自己產生 requirements.txt，直接在 Dockerfile 裡用 pipenv 動態生成 requirements.txt 來用，不過我自己還沒試過 Ref.","link":"/pipenv-intro/"},{"title":"589. N-ary Tree Preorder Traversal","text":"題目思路 樹的問題會先從遞迴來想比較直觀，首先找出最小可重複動作來作為 recursive case 先假設我們可以用題目給的 method 直接當作遞迴的函式，也就是說我們遞迴函式的回傳，是 preorder 排序的 node values 最小可重複動作：對於我這個 node 來說，回傳 preordered values Python 3 solution1234567def preorder(self, root: 'Node') -&gt; List[int]: if not root: return [] result = [root.val] for child in root.children or []: result.extend(self.preorder(child)) return result 假如用迭代的方式來解呢？ 用 stack, 把要處理的放入，迴圈內每次都拿一個出來，做 最小可重複動作，做到 stack 沒東西為止 注意在放入 child 的時候這邊是用 reverse order 來放，因為我到時候拿出來的時候想用 .pop()(O(1) 時間複雜度) 而不是 .pop(0)(O(n) 時間複雜度) Python 3 iterative solution12345678910111213def preorder(self, root: 'Node') -&gt; List[int]: if not root: return [] stack = [root] res = [] while stack: node = stack.pop() res.append(node.val) if not node.children: continue for child in reversed(node.children): stack.append(child) return res","link":"/n-ary-tree-preorder-traversal/"},{"title":"PostgreSQL/MySQL local docker 開發的初始 setup","text":"container run 起來之後：PostgreSQL: docker exec -it {db-container-name} psql -U postgres 以預設 user postgres 連進 DB create user {username} with password '{password}'; create database {database_name} with owner {username}; 大功告成，可以用 \\l 列出所有 database &amp; \\du 列出所有 user 來確認 P.S. 假如一開始忘了指定 database owner 或想改變 owner: alter database {database_name} owner to {owner_name}; MySQL: (以 5.7 為例) 環境變數須設置 MYSQL_ROOT_PASSWORD docker exec -it {db-container-name} mysql -p 以預設 user root 連進去，輸入上面環境變數設置的密碼 create user '{username}'@'localhost' identified by '{password}'; Use localhost due to working on the machine with MySQL. create database {database_name}; 確認： show databases; SELECT user FROM mysql.user;","link":"/postgresql-mysql-init-setup/"},{"title":"遞迴的時間複雜度算法","text":"快速解 (適用於遞迴函式內呼叫自己 &gt; 1 次) 看這個遞迴函式呼叫自己幾次，假設呼叫了 x 次 看看那些遞迴呼叫的深度。假如函式內呼叫自己兩次，深度各為 m、n，此時這個遞迴函式的總深度 h = m + n 時間複雜度為 O(x^h) 至少目前套用在幾個比較單純的遞迴式都成立，不確定複雜的是不是也成立 例子：Validate Binary Search Tree 詳細解 (遞迴樹)以 Unique Paths 的遞迴解為例： 12345678def uniquePaths(self, m: int, n: int) -&gt; int: def u_paths(i, j): if i &gt;= m or j &gt;= n: return 0 if i == m - 1 and j == n - 1: return 1 return u_paths(i + 1, j) + u_paths(i, j + 1) return u_paths(0, 0) 假設 m = 3, n = 2，遞迴樹如下 由圖可知，遞迴深度為 5 (= m + n) 要怎麼不用畫圖，用看的就得出深度？ 深度為根節點走到葉子節點的路徑長，我們可以看從 u_paths(0, 0) 開始，要走幾次才會結束： u_paths(i + 1, j) 這邊只需要看 i，要走 i + 1 = 1, 2, ..., m 共 m 次 走完 m 次之後還有 u_paths(i, j + 1)，要接著再走 j + 1 = 1, 2, ..., n 共 n 次 所以需要走 m + n 次才會結束 u_paths 合併遞迴結果的運算只需要一次加法，可以把時間消耗記做 1，也就是每個節點的時間消耗都是 1 所有節點的時間消耗總合就是這個函式的時間複雜度。第一層有 1 (= 2^0) 個節點，第二層有 2 (= 2^1) 個節點，第三層有 4 (= 2^2) 個節點，以此類推，假設此樹深度為 h，所有節點的時間消耗和為 2^0 + 2^1 + 2^2 + ... + 2^h，依據等比級數和的公式得出結果為 2^(h + 1) - 1 這邊的算法是假設這是一個滿二元樹來算，但其實這並不是一個滿二元樹 (像第四層就只有 7 個節點)，所以遞迴樹法並不嚴謹，只是一個估算，真要嚴謹分析的話可以再用 Substitution Method 或 Master Theorem 來驗證 由第二點，深度 h = m + n 所以時間複雜度為 O(2^(h + 1)) = O(2 * 2^h) = O(2^h) = O(2^(m + n))","link":"/recursion-time-complexity/"},{"title":"Remove Duplicates from Sorted List","text":"題目思路： 既然是 Linked List，我們可以宣告一個指標 curr 指向第一個 node，用 while 迴圈一次檢查一個 node (檢查完將指標移到下一個 node) 不能直接用 head 來移動，因為到時候回傳答案的時候需要回傳這個 head 設定 while 可以繼續檢查的條件：有時要先寫 while 的內容，才會比較確定 while 條件應該怎麼寫，這時可以先寫 while True:，等內容寫完再來改條件 寫 while 內容 假如 curr.val 跟下一個一樣，就把 next 接到下下個 12if curr.val == curr.next.val: curr.next = curr.next.next 但假如下下個也一樣呢？=&gt; 把上面的 if 改成 while，讓最後 curr.next 所指的 val 一定是不一樣的 改成 while 之後，檢查條件會被重複執行。因為 curr.next 有可能會是 None，所以條件改為while curr.val == (curr.next and curr.next.val): 離開 while 之後：curr = curr.next # 把指標移到下一個 node，以便下次的檢查 回去修改 while 條件：什麼條件成立我們才能繼續檢查(執行 while 內容)？ 首先 curr 不能是 None curr 有可能是 None，因為我們一直把它指向下一個 Node，到了盡頭 curr 就會是 None 即使 curr.next 是 None，還是可以順利執行迴圈內容 結論：條件為 while curr: 離開 while 之後就大功告成，回傳答案 head Python3 solution: 123456789101112# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextdef deleteDuplicates(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: curr = head # 等一下可以在 while 迴圈中移動的指標 while curr: while curr.val == (curr.next and curr.next.val): curr.next = curr.next.next curr = curr.next return head","link":"/remove-duplicates-from-sorted-list/"},{"title":"Reverse Linked List","text":"題目思路 因為是 linked list，我們可以使用 curr 當指標，沿著 linked list 的頭往後走，一邊改變 curr.next 的指向，而過程中必須對前一個和下一個都有所掌握，因為 curr 必須指向前一個，然後它本身必須換到下一個 所以我們會有三個變數：previous, curr, next 當 curr 是 head 時，previous 會是 None，這兩個可以先設定好。目標是一直改變 curr 的指向，讓 curr 一直走到 linked list 盡頭，變成 None 為止，所以 while 條件就是 當有 curr 的時候就做 Python 3 solution: 1234567891011121314# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextdef reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: previous = None curr = head while curr: next = curr.next curr.next = previous previous = curr curr = next return previous","link":"/reverse-linked-list/"},{"title":"Same Tree","text":"題目思路： 要比較所有相同位置的 node 的值是否一樣，可以把所有待比較的 node pair 丟到 stack 裡一一拿出來比較，全部比完都通過的話就是一樣的 tree 一個 pair 比較後會把下面的所有分支點繼續丟進 stack 等待比較，所以用 while stack: 只要有就繼續比，一直比到完 此為廣先搜尋 (Breadth-First Search) Python3 solution: 123456789101112131415161718# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef isSameTree(self, p: Optional[TreeNode], q: Optional[TreeNode]) -&gt; bool: stack = [(p, q)] while stack: p, q = stack.pop() if p and q and p.val == q.val: stack.extend([ (p.left, q.left), (p.right, q.right) ]) elif p or q: # 只有在 p, q 都是 None 的情況下才會通過，這代表這兩棵樹在那個位置都沒有葉子 return False return True 假設 p 有 n 個節點，寬度 w1，q 有 m 個節點，寬度 w2 時間複雜度：O(max(m, n)) 空間複雜度：O(max(w1, w2)) 因為是 BFS, stack 需儲存當前層次上的節點，故跟寬度成正比 類似題：Symmetric Tree 用 iterative 方法來解","link":"/same-tree/"},{"title":"Search Insert Position","text":"題目思路：最直覺是直接 iterate nums，不過題目指定要 O(log n)，所以用 binary search 才能達到 設定左右兩個指標作為可能答案範圍：[left, right]，目標是移動這兩個指標，縮小答案範圍，直到我們可以依此範圍找出答案為止 while left &lt; right: 設定 binary search 可繼續執行的條件 此時可能會想，要用 &lt; or &lt;= 呢？承上，我們的目的是縮小範圍到可以找到答案為止，也就是說當縮小到滿意的範圍，我們就可以跳出迴圈。所以我們只需要用 &lt;，因為當 left == right 的時候就會跳出迴圈，而這範圍已經足以讓我們找到答案了 當然要用 &lt;= 也是可以解的出來，程式碼會稍有不同，這邊只是記錄我理解起來比較順的思路 迴圈寫完後，檢查一下：最後 left 有可能會 &gt; right 嗎？ left 要 &gt; right，唯一可能是 left == right == mid 的情況配合 left = mid + 1，不過假如發生前者的情況就會跳出迴圈，所以不會有 left &gt; right 的情況發生，也就是說如果跳出迴圈，當時的條件一定是 left == right 看看 while 把 left &amp; right 收斂到最後幾個的時候，還會不會繼續收斂直到跳出迴圈，或是其實不會繼續收斂而發生無窮迴圈，關注下面兩行移動 left &amp; right 的程式碼 121. left = mid + 12. right = mid 剩最後三個：此時 mid 會是中間那個，上面兩種操作都有助於收斂範圍 剩最後兩個：此時 mid == left，上面兩種操作一樣可以收斂範圍 剩最後一個：此時 left == right，跳出迴圈 =&gt; 確保了不會造成無窮迴圈 Post processing: 跳出 while 後的情況為 left == right，這時可能的答案只剩一個元素，但它跟 target 是否相等或誰大誰小還不知道，這時我們再把該元素跟 target 比，就可以決定答案為何 Python 3 solution1234567891011def searchInsert(self, nums: List[int], target: int) -&gt; int: left, right = 0, len(nums) - 1 # 設定左右兩個指標作為可能答案範圍：[left, right] while left &lt; right: mid = (left + right) // 2 # Python3 不會有 integer overflow 的問題，所以可以直接 (left + right)，然後用 `//` 無條件捨去，避免小數 if nums[mid] == target: return mid if nums[mid] &lt; target: left = mid + 1 # 此時最小的可能答案為 `mid + 1` else: right = mid # 此時最大的可能答案為 `mid` return left + 1 if nums[left] &lt; target else left 參考文章：Come on, forget the binary search pattern/template! Try understand it! 類似題：704. Binary Search, First Bad Version延伸題：Find Peak Element","link":"/search-insert-position/"},{"title":"Single Number","text":"題目 因為只能用常數的額外空間，且 array 裡的數字除了目標之外都會有兩個，所以朝 bitwise operation 的方向想 把 array 裡所有數字接連做 bitwise operation，假如有兩個一樣的數字，他們就會抵銷變為 0，即使不是連著做也一樣，所以最後的結果就是那個落單的數字 可以想像所有數字都用二進位表示由上而下列在一起做計算，不管他們位置怎麼換結果都會一樣 (偶數個 1 會互相抵銷) Python3 solution: 12345def singleNumber(self, nums: List[int]) -&gt; int: r = 0 for i in nums: r ^= i return r","link":"/single-number/"},{"title":"Spring MVC 之 DispatcherServlet - url pattern設置問題 (/ vs. /*)","text":"最近把我的 project 轉為 spring mvc 的架構，想說可以順便用 spring 的 RESTful。Controller 的 method 大概如下： 123456@RequestMapping(value = \"/show_my_page\", method = RequestMethod.GET) public String showMyPage(Model model) { // do something return \"myPage\"; } 結果 Server 卻丟出類似如下的 error message：WARN PageNotFound:1114 - No mapping found for HTTP request with URI [/myWebApp/WEB-INF/views/myPage.jsp] in DispatcherServlet with name 'dispatcherServlet' 我的 jsp 路徑沒錯，google 了好一陣子也找不到解答，後來看 Spring in Action 第三版裡面建議針對DispatcherServlet 用如下的 url-pattern 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 不建議用以下這種 (我當時一開始的配置) 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 不過它的解釋我看不太懂，應該說它並沒有針對這兩個的不同做解釋。總之，我把 url-pattern 改為 / 之後，就可以正常顯示我的 jsp了 (感動 T^T) 自己的推測： url-pattern: /* DispatcherServlet 會攔截 web app 外部和內部所有的 request，所以當 View 將 request dispatch 給jsp 時會被攔截，而 DispatcherServlet 找不到對應的 method，因此拋出上面那個錯誤 url-pattern: / DispatcherServlet 會攔截 web app 外部所有的 request 而不會攔截內部的，所以 View 可以順利的將request dispatch 給 jsp 而不被 DispatcherServlet 攔截","link":"/spring-mvc-url-pattern/"},{"title":"Unique Paths","text":"題目思路 每走一步都會是一個 unique path，到終點的路線是由每一步所組成的，所以可以用遞迴的方式來想，最小的可重複動作就是一步，點 (i, j) 到終點的 unique path count 就是 (i + 1, j) 和 (i, j + 1) 的 unique path count 的和 最小可重複動作 return u_paths(i + 1, j) + u_paths(i, j + 1) 終止條件 1234if i &gt;= m or j &gt;= n: return 0if i == m - 1 and j == n - 1: return 1 已經在終點上了，unique path count 卻是 1，一開始可能會覺得有點怪，不過從終點左邊那個點來想，就不會怪了： 左邊那個點的 unique path count = (它的下面那點的 path count) + (它右邊那點的 path count) 下面那點：path count 為 0 右邊那點 (終點)：path count 必須是 1 遞迴解法如下，但時間複雜度 O(2^(m + n)) 太大了 (計算參考這篇) 123456789101112131415def uniquePaths(self, m: int, n: int) -&gt; int: def u_paths(i, j): \"\"\" i, j 為從 0 開始的坐標 @return 由 (i, j) 走到終點的 unique path count \"\"\" # 終止條件 if i &gt;= m or j &gt;= n: return 0 if i == m - 1 and j == n - 1: return 1 # 最小可重複動作 return u_paths(i + 1, j) + u_paths(i, j + 1) return u_paths(0, 0) 因為同一個點可能會走到很多次，我們可以把結果存在二維陣列，避免重複計算，以減少時間複雜度 Python3 solution: 12345678910111213141516171819202122def uniquePaths(self, m: int, n: int) -&gt; int: dp = [[None] * n for i in range(m)] # m * n 的二維陣列 def u_paths(i, j): \"\"\" i, j 為從 0 開始的坐標 @return 由 (i, j) 走到終點的 unique path count \"\"\" # 終止條件 if i &gt;= m or j &gt;= n: return 0 if i == m - 1 and j == n - 1: return 1 if dp[i][j]: return dp[i][j] # 最小可重複動作 dp[i][j] = u_paths(i + 1, j) + u_paths(i, j + 1) return dp[i][j] return u_paths(0, 0) 時間複雜度：O(m * n) 因為有記憶，每個點只會計算一次，共有 m * n 個點 空間複雜度：O(m * n) 維護 dp 所需空間。遞迴呼叫所需空間 m 和 n 可忽略 類似題： Fibonacci Number Unique Paths II","link":"/unique-paths/"},{"title":"使用 Dokku 將 Web App 部署在 DigitalOcean","text":"因為 Heroku 現在要收費了，原本放在上面用免費方案的 project 就需要找新的方法。於是找到了 Dokku，他的 GitHub page 介紹如下： Docker powered mini-Heroku. The smallest PaaS implementation you’ve ever seen. 的確是很傳神，因為使用方法跟 Heroku 很像，基本上可以從 Heroku 無痛遷移，差別在你需要用自己的 VM &amp; domain，配合 dokku 就可以在上面用 docker 管理你的 application，就像他的 about 寫的： A docker-powered PaaS that helps you build and manage the lifecycle of applications 這邊使用 DigitalOcean 的 droplet，因為他有兩個月 200 美金的試用 credits，假如只是短期測試專案的話也夠了，不然也可以兩個月換一個新帳號 😅 這邊稍微筆記一下把 Heroku 專案搬過來的過程： 在 DigitalOcean 創一個 droplet, 在上面照著文件的步驟做，droplet OS 需選擇 dokku 支援的版本 使用 subdomain 的步驟： dokku domains:set-global {domain} dokku domains:set {dokku_app_name} {subdomain.domain} 設定 domain 的 A record, CNAME A record: Host: @ Value: droplet IP CNAME Host: subdomain Value: {domain}. 看起來這個方法應該可以讓我們在同一個 droplet 裡，用不同的 subdomains 跑多個不同的 web apps。只要分別設定多個 CNAME 和對應的 dokku app domain 就好 流程：{subdomain_a.domain} 的 request 依循 IP 到了該 droplet 的 nginx，nginx 再將 request 導到 subdomain_a 對應的 dokku app 如果單純只想讓 {dokku_app_name}.{domain} 指到 dokku app，也可以只設定 A record: Host: dokku_app_name Value: droplet IP dokku config:set {dokku_app_name} KEY=value 可設定需要的環境變數 可以用 runtime.txt 指定 python 執行的版本","link":"/use-dokku-on-digitalocean/"},{"title":"Use Retrofit with Dagger - simple example","text":"Retrofit 和 Dagger 都是 Square 出的 library，網路上已經有很多相關介紹了，因為 Retrofit 的 REST API Interface 的實作建議採用 Singleton 的方式，所以搭配 Dagger 來管理是個蠻好的 paradigm 今天在這邊分享一個簡單的整合 example，希望可以讓第一次用且想要整合這兩個 libraries 的人快速上手，更 detail 的說明可以參考上面兩個連結~ DaggerModule.java - 提供 injection 的 module，在這裡提供 API Service 的 instance123456789101112131415@Module( injects = { ExampleActivity.class })public class DaggerModule { @Provides @Singleton public APIService provideAPIService() { return new RestAdapter.Builder() .setEndpoint(Constants.API_SERVICE_ENDPOINT) .build() .create(APIService.class); }} 上面的 APIService 就是我們 REST API 的 interface 可以把所有的 modules 加在這邊，如此 Dagger 在 compile 時就可以幫我們檢查所有的 modules 裡有沒有錯誤123456@Module( includes = { DaggerModule.class })public class WrapperModule {} ExampleApplication.java - 自己寫一支 custom 的 Application，維護 ObjectGraph，inject 的動作由它執行12345678910111213141516171819202122232425public class ExampleApplication extends Application { private ObjectGraph objectGraph; @Override public void onCreate() { super.onCreate(); objectGraph = ObjectGraph.create(new DaggerModule()); } /** * inject all injectable fields in this &lt;tt&gt;obj&lt;/tt&gt; * @param obj */ public void inject(Object obj) { objectGraph.inject(obj); } /** * @param activity * @return instance of ExampleApplication which this activity belongs to */ public static ExampleApplication from(Activity activity) { return (ExampleApplication) activity.getApplication(); }} 記得在 AndroidManifest.xml 的 &lt;application&gt; tag 加上 android:name 屬性，指定 custom Application 的 class BaseActivity.java - 之後我們寫的 Activity 只要繼承它，擁有 ＠inject 的屬性就會自動被注入123456789public abstract class BaseActivity extends Activity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); ExampleApplication.from(this).inject(this); }} ExampleActivity.java12345public class ExampleActivity extends BaseActivity { @Inject APIService apiService; ......} 接下來就可以在 ExampleActivity 中自由使用 apiService 啦！","link":"/use-retrofit-with-dagger/"},{"title":"Validate Binary Search Tree","text":"題目思路 樹的問題用遞迴來解相對上比較直覺，所以先試試遞迴解 拆解到最小單位來找 recursive case: 隨機取樹中一個點，判斷它是否 valid 大部分情況下會有上限和下限。以左邊的點為例，上限就是父節點的值，下限就是它所在的右子樹的父節點的值，所以這個值必須由上到下一層層傳遞下來。反之，右邊的點的話，就變成上限必須一層層傳遞下來 因為上下限必須用傳遞的，所以寫一個 function node_valid 接受上下限的參數 Python3 solution: 12345678910111213141516171819# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef isValidBST(self, root: Optional[TreeNode]) -&gt; bool: def node_valid(node, floor=float('-inf'), ceiling=float('inf')): if not node: return True v = node.val if v &lt;= floor or v &gt;= ceiling: return False if not node_valid(node.left, floor, v): return False if not node_valid(node.right, v, ceiling): return False return True return node_valid(root) 假設樹有 n 個 node 時間複雜度：O(n) 因為每個點都會做一次，而每次的複雜度為 O(1) 另一個算法可參考這邊的快速解： node_valid 的遞迴深度為這棵樹的深度 (兩次呼叫自己的深度的相加)，在樹為平衡的情況下，深度為 log2 n，所以複雜度為 O(2^(log2 n)) = O(n) 接下來嘗試用迭代解 可以用跟遞迴類似的思路，只是改成把要處理的 nodes 都放到 stack 裡，然後每次迴圈都從裡面拿一個出來做，一直做到 stack 為空。迴圈裡的內容就是 recursive case 因為 floor 和 ceiling 必須一直傳下去，所以跟 node 一起包成 tuple 放入 stack Python3 solution: 1234567891011121314151617181920# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightdef isValidBST(self, root: Optional[TreeNode]) -&gt; bool: stack = [(root, float('-inf'), float('inf'))] # node, floor, ceiling while stack: node, floor, ceiling = stack.pop() if not node: continue v = node.val if v &lt;= floor or v &gt;= ceiling: return False stack.extend([ (node.left, floor, v), (node.right, v, ceiling) ]) return True","link":"/validate-binary-search-tree/"},{"title":"為什麼 Python 的 in 用在 set 是 O(1) 時間複雜度？","text":"通常都會說 Python 的 set 內部是用 hash table 來實作，所以是 O(1)，但為什麼這樣就是 O(1)？ 當要判斷某個元素是否在 set 裡面時，它的 __hash__() 會被用來得到 hash 值，可以把這個 hash 值視為 set 底層實作的 array 的 index，Python 接著會用這個 hash 值去那個 array 的對應位置找，然後發現 array 沒有這個位置，或是找到對應 value，而這個過程跟 set 裡的元素個數無關，所以是 O(1) 而這邊說的 O(1) 是平均時間複雜度，最壞情況時間複雜度是 O(n)，它發生在不同元素產生相同 hash 的時候，也就是 hash collision。假如有兩個元素的 hash 發生 collision，他們就會被放在同一個 index，可以想像這個 index 的元素變成這兩個元素組成的 linked list，而最差的情況就是所有元素都發生 hash collision，等同於這個 set 變成一個 n 個元素的 linked list，所以判斷一個元素是否在裡面就需要 O(n) 時間複雜度了 參考資料：Why do sets in Python have an algorithmic complexity of O(1)?","link":"/why-python-set-o1/"},{"title":"為什麼 Python dict 的 get item operation 時間複雜度為 O(1) ？","text":"如果去 google，大部分查到的都會說因為 Python 會把 key 經過 hash function 運算，得到一個 dict 真正內部在使用的 key，從而找到對應的 value。而一個好的 hash function 它的運算所需時間是不會隨著 n 增加而變大的，所以 dict 的 get item operation 時間複雜度為 O(1) 。 不過我的疑惑是，經過 hash function 運算得到 key 之後，由這個 key 去找到 value 的時間複雜度是 O(1) 嗎？除非這個也是 O(1) 才能說整個 get item operation 是 O(1) 。 後來再多翻了一些說明，終於看到一兩個回答可以解釋這個疑惑。可以想像成今天我們有一個 array，我們只要知道 index 就可以知道要去哪裡找到對應的 value ( 因此是 O(1) )，經由 hash function 算出來的 key 就好像 array 的 index 一樣，只要看到這個 key 就知道要去哪裡找對應的 value，不會受 n 大小的影響，所以是 O(1) 另一個比較生活化的例子：hash function 算出來的 key，就好像你在圖書館要找書時用的索引，看到索引你就會知道書在哪一區、哪個櫃子裡，即使你需要照著圖書館的索引指示找一下才能找到，但這個過程所花的時間，跟圖書館有多少書沒有關係。 References: https://qr.ae/pvMCpM https://qr.ae/pvMCIv","link":"/why-dict-o1/"}],"tags":[{"name":"linked list","slug":"linked-list","link":"/tags/linked-list/"},{"name":"array","slug":"array","link":"/tags/array/"},{"name":"two pointers","slug":"two-pointers","link":"/tags/two-pointers/"},{"name":"sorting","slug":"sorting","link":"/tags/sorting/"},{"name":"stack","slug":"stack","link":"/tags/stack/"},{"name":"string","slug":"string","link":"/tags/string/"},{"name":"simulation","slug":"simulation","link":"/tags/simulation/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"tree","slug":"tree","link":"/tags/tree/"},{"name":"depth-first search","slug":"depth-first-search","link":"/tags/depth-first-search/"},{"name":"binary tree","slug":"binary-tree","link":"/tags/binary-tree/"},{"name":"recursion","slug":"recursion","link":"/tags/recursion/"},{"name":"bit manipulation","slug":"bit-manipulation","link":"/tags/bit-manipulation/"},{"name":"breadth-first search","slug":"breadth-first-search","link":"/tags/breadth-first-search/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"hash table","slug":"hash-table","link":"/tags/hash-table/"},{"name":"sliding window","slug":"sliding-window","link":"/tags/sliding-window/"},{"name":"matrix","slug":"matrix","link":"/tags/matrix/"},{"name":"dynamic programming","slug":"dynamic-programming","link":"/tags/dynamic-programming/"},{"name":"jwt","slug":"jwt","link":"/tags/jwt/"},{"name":"authentication","slug":"authentication","link":"/tags/authentication/"},{"name":"greedy","slug":"greedy","link":"/tags/greedy/"},{"name":"package management","slug":"package-management","link":"/tags/package-management/"},{"name":"pipenv","slug":"pipenv","link":"/tags/pipenv/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"postgresql","slug":"postgresql","link":"/tags/postgresql/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"binary search","slug":"binary-search","link":"/tags/binary-search/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"heroku","slug":"heroku","link":"/tags/heroku/"},{"name":"dokku","slug":"dokku","link":"/tags/dokku/"},{"name":"paas","slug":"paas","link":"/tags/paas/"},{"name":"binary search tree","slug":"binary-search-tree","link":"/tags/binary-search-tree/"}],"categories":[{"name":"Leetcode","slug":"Leetcode","link":"/categories/Leetcode/"},{"name":"Development Note","slug":"Development-Note","link":"/categories/Development-Note/"},{"name":"Project Management","slug":"Project-Management","link":"/categories/Project-Management/"},{"name":"System Design","slug":"System-Design","link":"/categories/System-Design/"},{"name":"Book Digest","slug":"Book-Digest","link":"/categories/Book-Digest/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"}]}